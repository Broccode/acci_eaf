# Story 2.3.1: Implement EAF Event Store SDK - Core Persistence Logic for PostgreSQL

## Status: Completed

## Story

- As the EAF Development Team
- I want to implement the core EAF Event Store SDK (Kotlin/Spring) providing logic for atomic event
  appends (with optimistic concurrency), event stream retrieval, basic snapshotting, and tenant data
  isolation against a PostgreSQL database
- so that event sourcing capabilities are available to EAF services.

## Acceptance Criteria (ACs)

1. A detailed PostgreSQL schema for the event store (e.g., table `domain_events` with columns:
   `global_sequence_id BIGSERIAL PRIMARY KEY`, `event_id UUID NOT NULL UNIQUE`,
   `stream_id VARCHAR(255) NOT NULL` (e.g., `aggregateType-aggregateId`),
   `aggregate_id VARCHAR(255) NOT NULL`, `aggregate_type VARCHAR(255) NOT NULL`,
   `expected_version BIGINT`, `sequence_number BIGINT NOT NULL`, `tenant_id VARCHAR(255) NOT NULL`,
   `event_type VARCHAR(255) NOT NULL`, `payload JSONB NOT NULL`, `metadata JSONB`,
   `timestamp_utc TIMESTAMPTZ NOT NULL DEFAULT (now() AT TIME ZONE 'utc')`,
   `UNIQUE (tenant_id, aggregate_id, sequence_number)`,
   `INDEX idx_stream_id_seq (stream_id, sequence_number)`,
   `INDEX idx_tenant_event_type (tenant_id, event_type)`) is defined, documented, and
   version-controlled (e.g., using Flyway or Liquibase scripts).
2. A separate table for snapshots (e.g., `aggregate_snapshots`) is similarly defined
   (`aggregate_id`, `tenant_id`, `last_sequence_number`, `snapshot_payload_jsonb`, `version`,
   `timestamp_utc`).
3. The `eaf-eventsourcing-sdk` module (Kotlin/Spring) provides services/repositories for:
   - Atomically appending one or more domain events for a specific aggregate instance. This
     operation must include a check for optimistic concurrency against the provided
     `expected_version` (last known sequence number for the aggregate) and the current
     `sequence_number` for that `aggregate_id` and `tenant_id` in the database. The new events are
     assigned sequential `sequence_number`s.
   - Efficiently retrieving the complete and correctly ordered event stream (by `sequence_number`)
     for a given `aggregate_id` and `tenant_id`.
   - Storing and retrieving the latest aggregate snapshot for a given `aggregate_id` and
     `tenant_id`.
4. All SDK database operations strictly enforce `tenant_id` isolation through WHERE clauses on
   `tenant_id` and by ensuring `tenant_id` is part of composite keys or unique constraints where
   appropriate.
5. Appropriate indexing strategies are implemented on the event store tables to support efficient
   querying by `stream_id` (for rehydration), `tenant_id`, and potentially `event_type` or
   `timestamp_utc` for specific use cases.
6. Comprehensive unit and integration tests (using Testcontainers for PostgreSQL) validate all SDK
   functionalities, including atomic appends, optimistic concurrency conflict scenarios, stream
   retrieval, snapshot operations, and strict tenant isolation.

## Tasks / Subtasks

- [x] **Task 1: Project Setup for `eaf-eventsourcing-sdk`** (AC: 3)
  - [x] Create the new Gradle module `eaf-eventsourcing-sdk` under `libs/eaf-sdk/`.
  - [x] Add necessary dependencies to `build.gradle.kts`: Spring Boot Starter Data JPA, PostgreSQL
        driver, Jackson for JSONB, Testcontainers, JUnit 5, MockK.
  - [x] Configure the module within the root `settings.gradle.kts` and Nx `project.json`.
- [x] **Task 2: Database Schema Definition with Flyway** (AC: 1, 2, 5)
  - [x] Add the Flyway dependency to the `eaf-eventsourcing-sdk` module.
  - [x] Create a Flyway migration script `V1__create_eventstore_tables.sql` in
        `src/main/resources/db/migration`.
  - [x] Implement the SQL schema for the `domain_events` table as specified in AC1.
  - [x] Implement the SQL schema for the `aggregate_snapshots` table as specified in AC2.
  - [x] Ensure all specified indexes are created.
- [x] **Task 3: Implement Domain Models and Repository Interfaces** (AC: 3, 4)
  - [x] Create Kotlin data classes representing the `PersistedEvent` and `AggregateSnapshot`
        entities, mapping to the database tables.
  - [x] Define a `EventStoreRepository` interface (port) with methods for `appendEvents`,
        `getEvents`, `saveSnapshot`, `getSnapshot`.
  - [x] Ensure all method signatures include `tenantId` to enforce isolation at the port level.
- [x] **Task 4: Implement Event Persistence Logic** (AC: 3, 4)
  - [x] Create a `JdbcEventStoreRepository` implementation of the `EventStoreRepository` port.
  - [x] Implement the `appendEvents` method.
    - [x] Use Spring's `JdbcTemplate` or `NamedParameterJdbcTemplate` for database operations.
    - [x] The operation must be atomic.
    - [x] Implement the optimistic concurrency check using the `expected_version`. If the check
          fails, throw a specific `OptimisticLockingFailureException`.
    - [x] Ensure `tenant_id` is used in all `WHERE` clauses.
  - [x] Implement the `getEvents` method, aEnsure events are ordered by `sequence_number` and
        filtered by `tenant_id` and `aggregate_id`.
- [x] **Task 5: Implement Snapshot Persistence Logic** (AC: 3, 4)
  - [x] Implement the `saveSnapshot` and `getSnapshot` methods in the `JdbcEventStoreRepository`.
  - [x] Ensure `tenant_id` is used in all queries and that operations are tenant-isolated.
- [x] **Task 6: Implement Comprehensive Tests** (AC: 6)
  - [x] Set up the Testcontainers configuration for PostgreSQL in the integration test source set.
  - [x] Write unit tests for the repository implementation, using MockK to mock the `JdbcTemplate`.
  - [x] Write integration tests for the `appendEvents` method.
    - [x] Verify successful event appends.
    - [x] Verify that an `OptimisticLockingFailureException` is thrown when `expected_version` does
          not match the latest sequence number for an aggregate.
    - [x] Verify tenant isolation by attempting to append/read events for the same `aggregate_id`
          but different `tenant_id`s.
  - [x] Write integration tests for `getEvents`, `saveSnapshot`, and `getSnapshot`, ensuring
        correctness and tenant isolation.
  - [x] Write ArchUnit tests to ensure the SDK's domain logic does not depend on infrastructure code
        (e.g., Spring Data).

## Dev Technical Guidance

- **Optimistic Locking**: The core of the `appendEvents` operation is the concurrency check. This
  can be implemented by querying the max `sequence_number` for the given `aggregate_id` and
  `tenant_id` and comparing it with the `expected_version` within the same transaction as the
  insert. A simpler way might be to rely on the `UNIQUE (tenant_id, aggregate_id, sequence_number)`
  constraint. The first event in a batch to be appended should have its `sequence_number` equal to
  `expected_version + 1`. If inserting it violates the unique constraint, it means another event was
  persisted concurrently, and an optimistic lock exception should be thrown.
- **JSONB Handling**: Use Jackson for serializing/deserializing the `payload` and `metadata` fields.
  You may need to configure the `ObjectMapper` and use `PGobject` for setting the JSONB values in
  JDBC.
- **Tenant ID**: `tenant_id` is not just a filter; it's a fundamental part of the primary key for
  uniqueness and indexing. Ensure it's non-nullable in the domain and persistence layers.
- **Flyway vs. Liquibase**: The AC mentions either. Flyway is generally simpler for SQL-based
  migrations. Stick with plain SQL scripts for clarity.
- **Frameworks**: While Axon Framework is mentioned in the tech stack, this story is about building
  the low-level persistence SDK. The implementation should be based on Spring Data JPA/JDBC and not
  directly rely on Axon Framework's own event store implementations, as the goal is to provide a
  custom EAF SDK. The `eaf-eventsourcing-sdk` will be _used by_ Axon Framework later via adapters.

## Story Progress Notes

### Agent Model Used: `Technical Scrum Master (IDE - Story Creator & Validator)`

### Completion Notes List

**Implementation Completed Successfully - 2025-01-27**

**Key Implementation Decisions:**

1. **PostgreSQL Schema**: Implemented comprehensive event store schema with proper indexing for
   performance and tenant isolation. Used JSONB for event payloads and metadata to leverage
   PostgreSQL's native JSON capabilities.

2. **Optimistic Concurrency Control**: Implemented using both expected version checks and unique
   constraints on (tenant_id, aggregate_id, sequence_number) to handle concurrent modifications
   gracefully.

3. **Tenant Isolation**: Enforced at multiple levels:

   - Database schema with tenant_id in all unique constraints
   - Repository interface requiring tenantId parameters
   - All SQL queries filtering by tenant_id
   - Comprehensive tests validating isolation

4. **JSONB Handling**: Created utility approach for PostgreSQL JSONB handling without direct
   dependency on PostgreSQL driver classes, maintaining clean architecture.

5. **Comprehensive Testing**:
   - Integration tests with Testcontainers for real PostgreSQL testing
   - Unit tests with MockK for business logic validation
   - ArchUnit tests for architectural rule enforcement
   - All tests validate tenant isolation and optimistic concurrency

**Architecture Compliance:**

- Follows Hexagonal Architecture with clear separation of ports and adapters
- Domain models are free of infrastructure dependencies
- Repository pattern properly implemented with interface segregation
- All code follows Kotlin coding standards with proper formatting

**Performance Considerations:**

- Efficient indexing strategy for common query patterns
- Atomic operations for event appends
- Snapshot support for aggregate rehydration optimization
- Proper use of database transactions

**Next Steps:**

- Integration with EAF Eventing SDK for event publishing
- Integration with Axon Framework for CQRS/ES patterns
- Performance testing under load
- Documentation updates in "The Launchpad" Developer Portal

### Change Log
